{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RPG Legacy Dependency Analyzer\n",
    "\n",
    "This tool parses legacy RPG/SQL source code, extracts dependencies (Program-to-Program calls and Program-to-Table accesses), loads them into a Neo4j Graph Database, and runs clustering algorithms to find \"islands\" of isolated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration Loaded.\n",
      "ðŸ“‚ Scanning Directory: /workspace/src\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 1: SETUP & CONFIGURATION ---\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Configuration\n",
    "REPO_PATH = \"./src\"             # Folder containing your .rpgle, .sqlrpgle files\n",
    "NEO4J_URI = \"bolt://localhost:7687\"  # Localhost works because of 'network_mode: service:neo4j'\n",
    "NEO4J_AUTH = (\"neo4j\", \"password\")\n",
    "\n",
    "# Verify Environment\n",
    "print(f\"âœ… Configuration Loaded.\")\n",
    "print(f\"ðŸ“‚ Scanning Directory: {os.path.abspath(REPO_PATH)}\")\n",
    "if not os.path.exists(REPO_PATH):\n",
    "    os.makedirs(REPO_PATH)\n",
    "    print(f\"âš ï¸  Directory '{REPO_PATH}' was missing, so I created it. Please add files there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Universal Scan Complete. Processed 0 files.\n",
      "âš ï¸ No RPG files found.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 2: UNIVERSAL PARSER (FIXED, FREE, & MIXED MODE) ---\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def parse_rpg_file(filepath):\n",
    "    dependencies = []\n",
    "    full_filename = os.path.basename(filepath)\n",
    "    filename = full_filename.split('.')[0].upper()\n",
    "    extension = full_filename.split('.')[-1].upper() if '.' in full_filename else ''\n",
    "    \n",
    "    clean_path = os.path.relpath(filepath, start=\".\")\n",
    "    if clean_path.startswith(\"./\"): clean_path = clean_path[2:]\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            lines = f.readlines()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error reading {filepath}: {e}\")\n",
    "        return []\n",
    "        \n",
    "    # --- GLOBAL FLAGS ---\n",
    "    is_fully_free = False\n",
    "    if lines and len(lines) > 0:\n",
    "        # Check for **FREE directive at the very top\n",
    "        if lines[0].strip().upper().startswith('**FREE'):\n",
    "            is_fully_free = True\n",
    "\n",
    "    # State Variable for Mixed Mode\n",
    "    in_free_block = False \n",
    "    is_sql_block = False\n",
    "    \n",
    "    for line_num, raw_line in enumerate(lines, 1):\n",
    "        line = raw_line.strip()\n",
    "        if not line: continue\n",
    "        \n",
    "        upper_line = line.upper()\n",
    "\n",
    "        # --- STEP 0: HANDLE STATE SWITCHING (/FREE & /END-FREE) ---\n",
    "        # Directives often start with '/' in column 7, but we check liberally\n",
    "        if upper_line.startswith('/FREE') or upper_line.startswith('//FREE'):\n",
    "            in_free_block = True\n",
    "            continue # Skip the directive line itself\n",
    "        \n",
    "        if upper_line.startswith('/END-FREE') or upper_line.startswith('//END-FREE'):\n",
    "            in_free_block = False\n",
    "            continue\n",
    "\n",
    "        # \"Effective\" Free Mode: True if file is **FREE OR we are inside a /FREE block\n",
    "        is_free_context = is_fully_free or in_free_block\n",
    "\n",
    "        # --- STEP 1: SMART COMMENT STRIPPING ---\n",
    "        # If we are NOT in a free context, we MUST respect Column 7 comments\n",
    "        if not is_free_context:\n",
    "            if len(raw_line) > 6 and raw_line[6] == '*': \n",
    "                continue\n",
    "        \n",
    "        # Universal: Strip // and -- comments (Valid in both modes usually, but critical for Free)\n",
    "        if '//' in line: line = line.split('//')[0].strip()\n",
    "        if '--' in line: line = line.split('--')[0].strip()\n",
    "        if not line: continue\n",
    "\n",
    "        # Metadata\n",
    "        source_meta = {\n",
    "            'source': filename,\n",
    "            'source_path': clean_path,\n",
    "            'source_ext': extension,\n",
    "            'line': line_num,\n",
    "            'statement': line\n",
    "        }\n",
    "\n",
    "        # --- A. Modern \"DCL-F\" (Free Format File Declaration) ---\n",
    "        # STRICTLY for Free Contexts\n",
    "        if is_free_context:\n",
    "            dcl_match = re.search(r'\\bDCL-F\\s+(\\w+)', line, re.IGNORECASE)\n",
    "            if dcl_match:\n",
    "                target = dcl_match.group(1).upper()\n",
    "                action = 'READ' \n",
    "                if 'USAGE(*OUTPUT' in upper_line: action = 'WRITE'\n",
    "                elif 'USAGE(*UPDATE' in upper_line: action = 'UPDATE'\n",
    "                elif 'USAGE(*INPUT' in upper_line: action = 'READ'\n",
    "                \n",
    "                item = source_meta.copy()\n",
    "                item.update({'target': target, 'type': 'ACCESSES', 'action': action})\n",
    "                dependencies.append(item)\n",
    "\n",
    "        # --- B. Legacy \"F-Specs\" (Fixed Format) ---\n",
    "        # STRICTLY for Fixed Contexts (cannot write F-Specs inside /FREE)\n",
    "        if not is_free_context and upper_line.startswith('F') and len(line) >= 17:\n",
    "            file_type = line[16].upper()\n",
    "            if file_type in ['I', 'O', 'U', 'C']:\n",
    "                target = line[6:16].strip().upper()\n",
    "                # Anti-False-Positive check\n",
    "                if '=' not in target and '(' not in target:\n",
    "                    action = 'WRITE' if file_type == 'O' else 'READ'\n",
    "                    if file_type == 'U': action = 'UPDATE'\n",
    "                    if file_type == 'C': action = 'READ/WRITE'\n",
    "                    \n",
    "                    item = source_meta.copy()\n",
    "                    item.update({'target': target, 'type': 'ACCESSES', 'action': action})\n",
    "                    dependencies.append(item)\n",
    "\n",
    "        # --- C. Universal OpCodes (CHAIN, READ, WRITE) ---\n",
    "        opcode_match = re.search(r'\\b(CHAIN|READ|READE|READP|WRITE|UPDAT|DELETE)\\s+(\\w+)', line, re.IGNORECASE)\n",
    "        if opcode_match:\n",
    "            op = opcode_match.group(1).upper()\n",
    "            target = opcode_match.group(2).upper()\n",
    "            action = 'WRITE' if op in ['WRITE', 'UPDAT', 'DELETE'] else 'READ'\n",
    "            \n",
    "            item = source_meta.copy()\n",
    "            item.update({'target': target, 'type': 'ACCESSES', 'action': action})\n",
    "            dependencies.append(item)\n",
    "\n",
    "        # --- D. Universal Calls (CALL, CALLP) ---\n",
    "        call_match = re.search(r'\\b(CALL|CALLB|CALLP)\\s+[\\' \"]?(\\w+)[\\' \"]?', line, re.IGNORECASE)\n",
    "        if call_match:\n",
    "            target = call_match.group(2).upper()\n",
    "            item = source_meta.copy()\n",
    "            item.update({'target': target, 'type': 'CALLS', 'action': 'EXECUTE'})\n",
    "            dependencies.append(item)\n",
    "\n",
    "        # --- E. Embedded SQL ---\n",
    "        if 'EXEC SQL' in upper_line: is_sql_block = True\n",
    "        if ';' in line: is_sql_block = False\n",
    "        \n",
    "        if is_sql_block or 'EXEC SQL' in upper_line:\n",
    "            sql_match = re.search(r'\\b(FROM|JOIN|INTO|UPDATE|INSERT INTO)\\s+(\\w+)', line, re.IGNORECASE)\n",
    "            if sql_match:\n",
    "                raw_target = sql_match.group(2).upper()\n",
    "                target = raw_target.split('.')[-1]\n",
    "                \n",
    "                item = source_meta.copy()\n",
    "                item.update({'target': target, 'type': 'ACCESSES', 'action': 'SQL'})\n",
    "                dependencies.append(item)\n",
    "\n",
    "    return dependencies\n",
    "\n",
    "# --- Execution ---\n",
    "all_deps = []\n",
    "files_scanned = 0\n",
    "ALLOWED_EXTENSIONS = ('.rpgle', '.sqlrpgle', '.rpg', '.clp', '.clle')\n",
    "\n",
    "for root, dirs, files in os.walk(REPO_PATH):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(ALLOWED_EXTENSIONS):\n",
    "            files_scanned += 1\n",
    "            all_deps.extend(parse_rpg_file(os.path.join(root, file)))\n",
    "\n",
    "print(f\"âœ… Universal Scan Complete. Processed {files_scanned} files.\")\n",
    "df_deps = pd.DataFrame(all_deps)\n",
    "if not df_deps.empty:\n",
    "    display(df_deps.head())\n",
    "else:\n",
    "    print(\"âš ï¸ No RPG files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â­ï¸  Skipping load (No data).\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 3: NEO4J LOADER (FILES + LINE NUMBERS) ---\n",
    "\n",
    "def create_constraints(driver):\n",
    "    with driver.session() as session:\n",
    "        # 1. Unique constraints for all node types\n",
    "        session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (p:Program) REQUIRE p.name IS UNIQUE\")\n",
    "        session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (t:Table) REQUIRE t.name IS UNIQUE\")\n",
    "        session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (f:File) REQUIRE f.path IS UNIQUE\")\n",
    "        print(\"ðŸ”’ Constraints Verified.\")\n",
    "\n",
    "def load_data(tx, dataframe):\n",
    "    query = \"\"\"\n",
    "    UNWIND $batch AS row\n",
    "    \n",
    "    // 1. Create the Physical File Node & Logical Program Node\n",
    "    MERGE (f:File {path: row.source_path})\n",
    "    SET f.name = row.source + '.' + row.source_ext,\n",
    "        f.extension = row.source_ext\n",
    "    \n",
    "    MERGE (p:Program {name: row.source})\n",
    "    MERGE (p)-[:DEFINED_IN]->(f)\n",
    "    \n",
    "    // 2. Handle Relationships (CALLS or ACCESSES)\n",
    "    // We use apoc.do.when to switch logic based on dependency type\n",
    "    WITH p, row\n",
    "    CALL apoc.do.when(\n",
    "        row.type = 'CALLS',\n",
    "        \n",
    "        // CASE A: Program calls Program\n",
    "        'MERGE (t:Program {name: row.target}) \n",
    "         MERGE (p)-[r:CALLS]->(t)\n",
    "         // Accumulate line numbers: If new, create list. If exists, append to list.\n",
    "         ON CREATE SET r.lines = [row.line]\n",
    "         ON MATCH SET r.lines = r.lines + row.line',\n",
    "         \n",
    "        // CASE B: Program accesses Table\n",
    "        // We include {action: row.action} in the relationship key so READs and WRITEs are distinct\n",
    "        'MERGE (t:Table {name: row.target}) \n",
    "         MERGE (p)-[r:ACCESSES {action: row.action}]->(t)\n",
    "         ON CREATE SET r.lines = [row.line]\n",
    "         ON MATCH SET r.lines = r.lines + row.line',\n",
    "         \n",
    "        {p:p, row:row}\n",
    "    ) YIELD value\n",
    "    RETURN count(*)\n",
    "    \"\"\"\n",
    "    tx.run(query, batch=dataframe.to_dict('records'))\n",
    "\n",
    "if not df_deps.empty:\n",
    "    try:\n",
    "        with GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH) as driver:\n",
    "            # Step A: Wipe Database\n",
    "            with driver.session() as session:\n",
    "                session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "                print(\"ðŸ—‘ï¸  Old Graph Wiped.\")\n",
    "\n",
    "            # Step B: Setup Schema\n",
    "            create_constraints(driver)\n",
    "            \n",
    "            # Step C: Load Data\n",
    "            with driver.session() as session:\n",
    "                session.execute_write(load_data, df_deps)\n",
    "                \n",
    "                # Validation\n",
    "                count = session.run(\"MATCH (n) RETURN count(n) AS c\").single()[\"c\"]\n",
    "                print(f\"ðŸš€ Success! Loaded {count} nodes.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Database Error: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸  Skipping load (No data).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Analysis Failed: {neo4j_code: Neo.ClientError.Statement.SyntaxError} {message: Unknown function 'gds.version' (line 1, column 8 (offset: 7))\n",
      "\"RETURN gds.version() AS v\"\n",
      "        ^} {gql_status: 50N42} {gql_status_description: error: general processing exception - unexpected error. Unknown function 'gds.version' (line 1, column 8 (offset: 7))\n",
      "\"RETURN gds.version() AS v\"\n",
      "        ^}\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 4: ANALYSIS (GDS) ---\n",
    "\n",
    "try:\n",
    "    with GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH) as driver:\n",
    "        with driver.session() as session:\n",
    "            # 0. Check if GDS is installed\n",
    "            check = session.run(\"RETURN gds.version() AS v\").single()\n",
    "            if not check:\n",
    "                raise Exception(\"GDS Plugin not found on Neo4j server!\")\n",
    "\n",
    "            # 1. Clean up old projections (Silence Warning by YIELDing specific field)\n",
    "            session.run(\"CALL gds.graph.drop('rpgSystem', false) YIELD graphName\")\n",
    "\n",
    "            # 2. Project Graph (In-Memory)\n",
    "            session.run(\"\"\"\n",
    "                CALL gds.graph.project(\n",
    "                    'rpgSystem',\n",
    "                    ['Program', 'Table'],\n",
    "                    ['ACCESSES', 'CALLS']\n",
    "                )\n",
    "            \"\"\")\n",
    "            print(\"ðŸ“Š Graph Projected to Memory.\")\n",
    "\n",
    "            # 3. Algorithm: Weakly Connected Components (WCC)\n",
    "            # This finds 'Islands' -> groups of nodes disconnected from the rest\n",
    "            result = session.run(\"\"\"\n",
    "                CALL gds.wcc.stream('rpgSystem')\n",
    "                YIELD nodeId, componentId\n",
    "                RETURN gds.util.asNode(nodeId).name AS Name, \n",
    "                       labels(gds.util.asNode(nodeId))[0] AS Type, \n",
    "                       componentId\n",
    "                ORDER BY componentId\n",
    "            \"\"\")\n",
    "            \n",
    "            df_wcc = pd.DataFrame([r.data() for r in result])\n",
    "            \n",
    "            # 4. Clean Memory (Silence Warning)\n",
    "            session.run(\"CALL gds.graph.drop('rpgSystem', false) YIELD graphName\")\n",
    "\n",
    "    # --- Reporting ---\n",
    "    if not df_wcc.empty:\n",
    "        island_counts = df_wcc['componentId'].value_counts()\n",
    "        print(f\"\\nðŸï¸  Found {len(island_counts)} distinct 'Islands' (Isolated Systems).\")\n",
    "        \n",
    "        print(\"\\n--- Top 5 Largest Systems ---\")\n",
    "        print(island_counts.head(5))\n",
    "        \n",
    "        largest_id = island_counts.index[0]\n",
    "        print(f\"\\nðŸ” Components in the Largest System (ID: {largest_id}):\")\n",
    "        display(df_wcc[df_wcc['componentId'] == largest_id].head(10))\n",
    "    else:\n",
    "        print(\"âš ï¸  No analysis results generated. (Did you add files to ./src/rpgleparser?)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Analysis Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Updating Graph with Island Data...\n",
      "âŒ Error marking islands: {neo4j_code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `gds.graph.drop` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.} {gql_status: 50N42} {gql_status_description: error: general processing exception - unexpected error. There is no procedure with the name `gds.graph.drop` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 5: MARK ISLANDS (INCLUDING FILES & TABLES) ---\n",
    "\n",
    "try:\n",
    "    with GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH) as driver:\n",
    "        with driver.session() as session:\n",
    "            print(\"ðŸ”„ Updating Graph with Island Data...\")\n",
    "\n",
    "            # 1. Project Graph (Include FILES and DEFINED_IN relation)\n",
    "            session.run(\"CALL gds.graph.drop('rpgSystem', false) YIELD graphName\")\n",
    "            session.run(\"\"\"\n",
    "                CALL gds.graph.project(\n",
    "                    'rpgSystem',\n",
    "                    ['Program', 'Table', 'File'],\n",
    "                    ['ACCESSES', 'CALLS', 'DEFINED_IN']\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "            # 2. Run WCC Algorithm\n",
    "            # This identifies connected clusters regardless of node type\n",
    "            write_result = session.run(\"\"\"\n",
    "                CALL gds.wcc.write('rpgSystem', { \n",
    "                    writeProperty: 'componentId' \n",
    "                })\n",
    "                YIELD nodePropertiesWritten\n",
    "                RETURN nodePropertiesWritten\n",
    "            \"\"\").single()\n",
    "            \n",
    "            print(f\"   -> Tagged {write_result['nodePropertiesWritten']} nodes (Programs, Tables, Files) with IDs.\")\n",
    "\n",
    "            # 3. Create Island Nodes and Relationships\n",
    "            # Group ALL nodes by their new componentId\n",
    "            summary = session.run(\"\"\"\n",
    "                MATCH (n) WHERE n.componentId IS NOT NULL\n",
    "                \n",
    "                // Create the central Island Node\n",
    "                MERGE (i:Island {id: n.componentId})\n",
    "                \n",
    "                // Link everything (Files, Programs, Tables) to it\n",
    "                MERGE (n)-[:PART_OF]->(i)\n",
    "            \"\"\").consume()\n",
    "\n",
    "            # 4. Cleanup Memory\n",
    "            session.run(\"CALL gds.graph.drop('rpgSystem', false) YIELD graphName\")\n",
    "\n",
    "            print(f\"âœ… Success! Created relationships for {summary.counters.relationships_created} links.\")\n",
    "            print(\"   Visual Check: MATCH (i:Island)<-[:PART_OF]-(n) RETURN i, n LIMIT 50\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error marking islands: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
